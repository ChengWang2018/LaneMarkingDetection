{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-18T22:55:58.873922Z",
     "end_time": "2023-05-18T22:58:26.844166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Init NuScenes. Requires the dataset to be stored on disk.\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.map_expansion.map_api import NuScenesMap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "current_path = os.getcwd()\n",
    "parent = os.path.dirname(current_path)\n",
    "dataroot = parent + '/data/sets/nuscenes/'\n",
    "\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot=dataroot, verbose=False)\n",
    "\n",
    "# find a straight road for resolution determination\n",
    "scene_id = 509\n",
    "\n",
    "# load map, the corresponding map to the scene\n",
    "nusc_map = NuScenesMap(dataroot=dataroot, map_name='boston-seaport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get all samples in the scene\n",
    "sensor = 'CAM_FRONT'\n",
    "layer_names = ['road_segment', 'lane', 'ped_crossing', 'walkway', 'stop_line', 'carpark_area']\n",
    "current_sample = nusc.get('sample', nusc.scene[scene_id]['first_sample_token'])\n",
    "samples = []\n",
    "ego_poses = nusc_map.render_egoposes_on_fancy_map(nusc, scene_tokens=[nusc.scene[scene_id]['token']], verbose=False)\n",
    "while not current_sample[\"next\"] == \"\":\n",
    "    samples.append(current_sample)\n",
    "    # Update the current sample with the next sample\n",
    "    current_sample = nusc.get('sample', current_sample[\"next\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T22:58:26.819863Z",
     "end_time": "2023-05-18T22:58:30.717813Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import descartes\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.utils.geometry_utils import view_points\n",
    "from shapely.geometry import Polygon\n",
    "from PIL import Image\n",
    "from clip_points_behind_camera import clip_points_behind_camera\n",
    "from LaneDetection import LaneDetection, NuSceneProcessing\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "near_plane = 1e-8\n",
    "#lane_record = nusc_map.get_arcline_path(closest_lane)\n",
    "current_sample = samples[14] # chose one for an example in that scene\n",
    "cam_token = current_sample['data'][sensor]\n",
    "cam_front_data = nusc.get('sample_data', cam_token)\n",
    "ego_pos = nusc.get(\"ego_pose\", cam_front_data[\"ego_pose_token\"])\n",
    "cs_record = nusc.get('calibrated_sensor', cam_front_data['calibrated_sensor_token'])\n",
    "cam_intrinsic = np.array(cs_record['camera_intrinsic'])\n",
    "cam_path = nusc.get_sample_data_path(cam_token)\n",
    "im = Image.open(cam_path)\n",
    "im_size = im.size\n",
    "\n",
    "scene_record = nusc.get('scene', current_sample['scene_token'])\n",
    "log_record = nusc.get('log', scene_record['log_token'])\n",
    "log_location = log_record['location']\n",
    "assert nusc_map.map_name == log_location, \\\n",
    "    'Error: NuScenesMap loaded for location %s, should be %s!' % (nusc_map.map_name, log_location)\n",
    "\n",
    "closest_lane_token = nusc_map.get_closest_lane(ego_pos['translation'][0], ego_pos['translation'][1], radius=2)\n",
    "closest_lane = None\n",
    "try:\n",
    "    closest_lane = nusc_map.get(\"lane\", closest_lane_token)\n",
    "    nusc_map.render_record(\"lane\", closest_lane_token)\n",
    "    # nusc_map.render_map_in_image(nusc, current_sample['token'], layer_names=layer_names, camera_channel=sensor)\n",
    "\n",
    "except KeyError as e:\n",
    "    closest_lane_connector = nusc_map.get(\"lane_connector\", closest_lane_token)\n",
    "\n",
    "point_xy = [] # points in the real world\n",
    "points_img = [] # points in the image\n",
    "# we skip lane connector\n",
    "if closest_lane is not None:\n",
    "    poly = nusc_map.get(\"polygon\", closest_lane['polygon_token'])\n",
    "\n",
    "    for point in poly['exterior_node_tokens']:\n",
    "        node = nusc_map.get('node', point)\n",
    "        point_xy.append([node['x'], node['y']])\n",
    "\n",
    "    polygon = Polygon(point_xy)\n",
    "    point_xy = np.array(point_xy)\n",
    "\n",
    "    # Init axes.\n",
    "    fig = plt.figure(figsize=(9, 16))\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    ax.set_xlim(0, im_size[0])\n",
    "    ax.set_ylim(0, im_size[1])\n",
    "    ax.imshow(im)\n",
    "\n",
    "    # Convert polygon nodes to pointcloud with 0 height.\n",
    "    points = np.array(polygon.exterior.xy)\n",
    "    points = np.vstack((points, np.zeros((1, points.shape[1]))))\n",
    "    # Transform into the ego vehicle frame for the timestamp of the image.\n",
    "    points = points - np.array(ego_pos['translation']).reshape((-1, 1))\n",
    "    points = np.dot(Quaternion(ego_pos['rotation']).rotation_matrix.T, points)\n",
    "    # Transform into the camera.\n",
    "    points = points - np.array(cs_record['translation']).reshape((-1, 1))\n",
    "    points = np.dot(Quaternion(cs_record['rotation']).rotation_matrix.T, points)\n",
    "\n",
    "    points = clip_points_behind_camera(points, near_plane)\n",
    "\n",
    "    # Take the actual picture (matrix multiplication with camera-matrix + renormalization).\n",
    "    points = view_points(points, cam_intrinsic, normalize=True)\n",
    "    points = points[:2, :]\n",
    "    points = [(p0, p1) for (p0, p1) in zip(points[0], points[1])]\n",
    "    polygon_proj = Polygon(points)\n",
    "    label = 'LaneMarking'\n",
    "    ax.add_patch(descartes.PolygonPatch(polygon_proj, fc='r', alpha=0.5,\n",
    "                                        label=label))\n",
    "    # Display the image.\n",
    "    plt.axis('off')\n",
    "    ax.invert_yaxis()\n",
    "    points_img = points\n",
    "    # plt.figure()\n",
    "    # plt.plot(point_xy[:,0], point_xy[:,1])\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T22:58:30.698391Z",
     "end_time": "2023-05-18T22:58:33.935965Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "points_img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T22:58:33.934965Z",
     "end_time": "2023-05-18T22:58:33.941569Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "color = (0, 255, 0)\n",
    "thickness = 2\n",
    "image = cv2.imread(cam_path)\n",
    "for inx in range(1, len(points_img) - 3):\n",
    "    cv2.line(image, (int(points_img[inx][0]), int(points_img[inx][1])), (int(points_img[inx+1][0]), int(points_img[inx+1][1])),\n",
    "             color=color, thickness=thickness)\n",
    "plt.imshow(image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T22:58:34.171468Z",
     "end_time": "2023-05-18T22:58:34.417111Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# transform image to perspective\n",
    "import cv2\n",
    "lane_detection = LaneDetection()\n",
    "source_points = lane_detection.source_points\n",
    "image = cv2.imread(cam_path)\n",
    "img = lane_detection.draw_polygon_on_image(source_points, image)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# compute the perspective transform matrix and then apply it\n",
    "# the method refers to https://github.com/Ayanzadeh93/Udacity-Advance-Lane-detection-of-the-road\n",
    "M = lane_detection.M\n",
    "points_in_reality = point_xy\n",
    "pp = []\n",
    "for p in points_img:\n",
    "    persepctive_points = np.array([p[0], p[1]], dtype=float)\n",
    "    point = cv2.perspectiveTransform(persepctive_points.reshape(-1, 1, 2), M)\n",
    "    pp.append(point)\n",
    "points_on_img = pp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T22:58:34.418112Z",
     "end_time": "2023-05-18T22:58:34.537329Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "points_in_reality"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T22:58:34.432359Z",
     "end_time": "2023-05-18T22:58:34.560548Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "points_on_img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T22:58:34.450833Z",
     "end_time": "2023-05-18T22:58:34.560548Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pix_per_meter_x = abs((points_on_img[0][0][0][0]- points_on_img[3][0][0][0])/(points_in_reality[0][1] - points_in_reality[3][1]))\n",
    "Lh = np.linalg.inv(np.matmul(M, cam_intrinsic))\n",
    "pix_per_meter_y = pix_per_meter_x * np.linalg.norm(Lh[:,0]) / np.linalg.norm(Lh[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T22:58:34.465536Z",
     "end_time": "2023-05-18T22:58:34.560548Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "1/pix_per_meter_x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T22:58:34.486048Z",
     "end_time": "2023-05-18T22:58:34.561560Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "1/pix_per_meter_y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T22:17:36.075287Z",
     "end_time": "2023-05-18T22:17:36.119290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T20:08:57.695015Z",
     "end_time": "2023-05-18T20:08:57.710889Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
